  GSS = Great Salt Lake Sediment

mkdir /srv/data/16S/projects/GSS
cd /srv/data/16S/projects/GSS

forward=$(find /srv/data/16S/raw_data/20190708_16S-V4_PE250/ -maxdepth 1 -type f -regex ".*BRB.*_R1_.*")
reverse=$(find /srv/data/16S/raw_data/20190708_16S-V4_PE250/ -maxdepth 1 -type f -regex ".*BRB.*_R2_.*")
for file in ${forward[@]}; do from=$file; IFS="_ " read -a array <<< $(basename $file); sample=${array[0]}; to="/srv/data/16S/projects/GSS/${sample}.20.forward.fastq.gz"; ln -sv $from $to; done
for file in ${reverse[@]}; do from=$file; IFS="_ " read -a array <<< $(basename $file); sample=${array[0]}; to="/srv/data/16S/projects/GSS/${sample}.20.reverse.fastq.gz"; ln -sv $from $to; done

forward=$(find /srv/data/16S/raw_data/20190708_16S-V4_PE250/ -maxdepth 1 -type f -regex ".*Marina.*_R1_.*")
reverse=$(find /srv/data/16S/raw_data/20190708_16S-V4_PE250/ -maxdepth 1 -type f -regex ".*Marina.*_R2_.*")
for file in ${forward[@]}; do from=$file; IFS="_ " read -a array <<< $(basename $file); sample=${array[0]}; to="/srv/data/16S/projects/GSS/${sample}.20.forward.fastq.gz"; ln -sv $from $to; done
for file in ${reverse[@]}; do from=$file; IFS="_ " read -a array <<< $(basename $file); sample=${array[0]}; to="/srv/data/16S/projects/GSS/${sample}.20.reverse.fastq.gz"; ln -sv $from $to; done


make new GSL-sediment directory in my user directory and link files to that
mkdir GSL-sediment
cd GSL-sediment
ln -svi /srv/data/16S/projects/GSS/* ./
  
  srun readstats.py --csv -o readstats.csv ./*.20.* &
  less readstats.csv
--> all good

Remove primers:
  nano decontam.sh
#! /bin/sh
#SBATCH -J GSS.decontam
reads_path="/home/bbrazelton/GSL-sediment/";
files=$(find -L ${reads_path} -type f -regex ".*\.20.forward\.fastq.*");
for file in ${files[@]}; do
file=$(basename ${file});
IFS=". " read -a array <<< ${file};
sample=${array[0]};
forward="${reads_path}/${sample}.20.forward.fastq.gz";
reverse="${reads_path}/${sample}.20.reverse.fastq.gz";
cutadapt --discard-trimmed --error-rate 0.10 -a ATTAGAWACCCVHGTAGTCCGGCTGACTGACT -A TTACCGCGGCMGCTGGCACACAATTACCATA -g ^TTAGAWACCCVHGTAGTCCGGCTGACTGACT -G ^TACCGCGGCMGCTGGCACACAATTACCATA -o ${sample}.20.forward.decontam.fastq.gz -p ${sample}.20.reverse.decontam.fastq.gz ${forward} ${reverse} > ${sample}.cutadapt.log
done

sbatch decontam.sh

grep "Pairs written (passing filters):" *.log > passed_filter.txt
less passed_filter.txt
--> ~94-98% passed

screen -S GSS
srun --pty R
library('dada2')
library('ShortRead')
library('ggplot2')
library('grid')
library('gridExtra')

path <- getwd()
reads <- list.files(path)
fastqs <- sort(reads[grepl('.fastq+', reads)])
ff <- fastqs[grepl('forward', fastqs)]
rf <- fastqs[grepl('reverse', fastqs)]
samples <- sapply(strsplit(ff, '[.]'), '[', 1)
ff <- paste0(path, '/', ff)
rf <- paste0(path, '/', rf)

n <- sample(length(ff), 4)
forward_plots <- list()
reverse_plots <- list()
for (i in 1:length(n)) {
  sample_index <- n[i]
  fp <- plotQualityProfile(ff[sample_index])
  rp <- plotQualityProfile(rf[sample_index])
  fp <- fp + ggtitle(samples[sample_index])
  rp <- rp + ggtitle(samples[sample_index])
  forward_plots[[i]] <- fp
  reverse_plots[[i]] <- rp
}

png(filename="forward_plots.png")
grid.arrange(grobs=forward_plots)
dev.off()
png(filename="reverse_plots.png")
grid.arrange(grobs=reverse_plots)
dev.off()

######
run remaining commands with r script:
  
  nano dada.r

#!/usr/bin/Rscript
library('dada2')
library('ShortRead')
library('ggplot2')
library('grid')
library('gridExtra')

path <- getwd()
reads <- list.files(path)
fastqs <- sort(reads[grepl('.fastq+', reads)])
ff <- fastqs[grepl('forward', fastqs)]
rf <- fastqs[grepl('reverse', fastqs)]
samples <- sapply(strsplit(ff, '[.]'), '[', 1)
ff <- paste0(path, '/', ff)
rf <- paste0(path, '/', rf)

ff.filt <- paste0(path, '/', samples, '.forward.trimmed.filtered.fastq.gz')
rf.filt <- paste0(path, '/', samples, '.reverse.trimmed.filtered.fastq.gz')
filtered <- filterAndTrim(ff, ff.filt, rf, rf.filt, maxN=0, maxEE=3, truncQ=2, compress=TRUE, verbose=TRUE, matchIDs=TRUE, rm.phix=TRUE)
ff.derep <- derepFastq(ff.filt, verbose=TRUE)
rf.derep <- derepFastq(rf.filt, verbose=TRUE)
names(ff.derep) <- samples
names(rf.derep) <- samples
n <- sample(length(ff), 5)
ff.err <- learnErrors(ff.derep[n], errorEstimationFunction=loessErrfun, randomize=FALSE, multithread=TRUE)
rf.err <- learnErrors(rf.derep[n], errorEstimationFunction=loessErrfun, randomize=FALSE, multithread=TRUE)
ff.dada <- dada(ff.derep, err=ff.err, pool=TRUE, multithread=TRUE)
rf.dada <- dada(rf.derep, err=rf.err, pool=TRUE, multithread=TRUE)
merged <- mergePairs(ff.dada, ff.derep, rf.dada, rf.derep, verbose=TRUE, maxMismatch=0, trimOverhang=FALSE, justConcatenate=FALSE)
seqtable <- makeSequenceTable(merged, orderBy='abundance')
seqtable.nochim <- removeBimeraDenovo(seqtable, method="consensus", verbose=TRUE)
save.image()

srun -p highmem --mem 200G Rscript dada.r &

screen -S GSS
srun -p highmem --mem 100G --pty R
library('dada2')
library('ShortRead')
library('ggplot2')
library('grid')
library('gridExtra')

dim(seqtable)
[1]    8 3373

table(nchar(colnames(seqtable)))
250  251  252  253  254  255  256  257  261  264  292  293  357  365  377  395
9    2  127 2850  331   30    8    1    3    1    1    5    1    1    1    1
419
1

getN <- function(x) sum(getUniques(x))
track <- cbind(sapply(ff.dada, getN), sapply(merged, getN), rowSums(seqtable.nochim))
colnames(track) <- c("denoised", "merged", "chimera-checked")
rownames(track) <- samples
track

denoised merged chimera-checked
BRB17      138913 124516          119852
BRB19      120469 114361          112295
BRB22       89933  84516           81873
BRB24      150672 140236          127608
Marina13    85710  81687           77630
Marina26    73239  67559           65586
Marina27    67577  59746           56431
Marina3    113648 108725          106976

refdb <- '/srv/databases/markers/silva/dada2/silva_nr_v132_train_set.fa.gz'
taxa <- assignTaxonomy(seqtable.nochim, refdb, tryRC=FALSE, minBoot=50, verbose=TRUE)
colnames(taxa) <- c("Domain", "Phylum", "Class", "Order", "Family", "Genus")

library(phyloseq)
merged = phyloseq(otu_table(seqtable.nochim, taxa_are_rows=FALSE), tax_table(taxa))
write.csv(tax_table(merged), file="GSS-tax-table.csv", quote=FALSE)
write.csv(t(otu_table(merged)), file="GSS-otu-table.csv", quote=FALSE)
GSS <- phyloseq(otu_table(seqtable.nochim, taxa_are_rows=FALSE), tax_table(taxa))
save(GSS, file='GSS.dat')
quit()

srun count_cat_tax_csv.py -t GSS-tax-table.csv -c GSS-otu-table.csv -o GSS-otu-tax-table.csv

srun -p highmem --mem 100G --pty R
library(phyloseq)
library('ggplot2')
theme_set(theme_bw())
library('vegan')
library('grid')
library('ggrepel')

GSS
otu_table()   OTU Table:         [ 2789 taxa and 8 samples ]
tax_table()   Taxonomy Table:    [ 2789 taxa by 6 taxonomic ranks ]

meta.table <- read.csv("GSS-sample-info.csv", row.names=1)
sample_data(GSS) = meta.table
GSS
otu_table()   OTU Table:         [ 2789 taxa and 8 samples ]
sample_data() Sample Data:       [ 8 samples by 2 sample variables ]
tax_table()   Taxonomy Table:    [ 2789 taxa by 6 taxonomic ranks ]

nmds.horn = ordinate(GSS, method='NMDS', distance='horn') 
nmds.horn
Stress:     0.02544913
Stress type 1, weak ties
Two convergent solutions found after 20 tries

png(filename='GSS_horn_nmds_labeled.png', width=1000, height=1000)
plot_ordination(GSS, nmds.horn, type='samples', color='Location') + theme_bw() + theme(text=element_text(size=16)) + coord_fixed(ratio=1) + geom_point(size = 6) + theme(text=element_text(size=16)) + geom_text(aes(label=Sample_ID), size=4, nudge_x=0.02)
dev.off()

png(filename='GSS_horn_nmds.png', width=1000, height=1000)
plot_ordination(GSS, nmds.horn, type='samples', color='Location') + theme_bw() + theme(text=element_text(size=16)) + coord_fixed(ratio=1) + geom_point(size = 6) + theme(text=element_text(size=16))
dev.off()

# plot alpha diversity
library(phyloseq)
GSS
otu_table()   OTU Table:         [ 2789 taxa and 8 samples ]
sample_data() Sample Data:       [ 8 samples by 2 sample variables ]
tax_table()   Taxonomy Table:    [ 2789 taxa by 6 taxonomic ranks ]

png(filename='GSS_richness.png', width=1000, height=1000)
plot_richness(GSS)
dev.off()

# edited the metadata table to order the samples from North to South
meta.table <- read.csv("GSL_metadata_Feb2019.csv", row.names=1)
sample_data(GSL4) = meta.table

png(filename='GSL4_richness_v1.png', width=1000, height=1000)
plot_richness(GSL4, x="N_S_location", color="Depth.category", measures=c("Observed", "Shannon", "InvSimpson"))
dev.off()

png(filename='GSL4_richness_v2.png', width=1000, height=1000)
plot_richness(GSL4, x="N_S_location", color="Season", measures=c("Observed", "Shannon", "InvSimpson")) + facet_grid(~Depth.category)
dev.off()

png(filename='GSL4_richness_v3.png', width=1000, height=1000)
plot_richness(GSL4, x="N_S_location", color="Depth.category", measures=c("Observed", "Shannon", "InvSimpson")) + facet_grid(~Season)
dev.off()

May2018 = subset_samples(GSL4, Season=="2018-May")
png(filename='GSL4_richness_v4.png', width=1000, height=1000)
plot_richness(May2018, x="N_S_location", color="Depth.category", measures=c("Observed", "Shannon", "InvSimpson"))
dev.off()
